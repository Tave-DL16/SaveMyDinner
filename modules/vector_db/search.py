"""
modules.vector_db.search
ì‘ì„±ì: ì¶”ìœ¤ì„œ
ê¸°ëŠ¥: ìì·¨ìƒ/1ì¸ ê°€êµ¬ ë§ì¶¤í˜• ë ˆì‹œí”¼ ì •ì œ ë° ì¤‘ë³µ ì œê±° ê²€ìƒ‰ ì—”ì§„
"""
import chromadb
import json
import re
import os
from sentence_transformers import SentenceTransformer
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()

class RecipeSearcher:
    def __init__(self, db_path="./modules/vector_db/vectordb_recipes"):
        """
        ì´ˆê¸°í™”: ë¡œì»¬ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ë° ChromaDB ì—°ê²°
        """

        # 1. HuggingFaceì˜ í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ (768ì°¨ì›)
        self.model = SentenceTransformer('jhgan/ko-sroberta-multitask', device='cpu')

        # 2. OpenAI API ì„¤ì •
        api_key = os.getenv('OPENAI_API_KEY')
        if api_key:
            self.openai_client = OpenAI(api_key=api_key)
            print("âœ… OpenAI API ì—°ê²° ì™„ë£Œ")
        else:
            print("âš ï¸ OPENAI_API_KEY not found - LLM ì •ì œ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤")
            self.openai_client = None

        # 3. ChromaDB í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
        self.client = chromadb.PersistentClient(path=db_path)

        # 4. ì»¬ë ‰ì…˜ ë¡œë“œ
        try:
            self.collection = self.client.get_collection(name="recipes_local_cosine")
            print(f"âœ… 'recipes_local_cosine' ì»¬ë ‰ì…˜ ë¡œë“œ ì™„ë£Œ. (ë°ì´í„°: {self.collection.count()}ê°œ)")
        except Exception as e:
            print(f"âŒ ì»¬ë ‰ì…˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def clean_with_llm(self, raw_name):
        """OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í™˜ê° í˜„ìƒì„ ë°©ì§€í•˜ê³  í•µì‹¬ ìš”ë¦¬ëª…ë§Œ ì •í™•íˆ ì¶”ì¶œ"""
        
        # OpenAIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìœ¼ë©´ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì²´
        if self.openai_client is None:
            print(f"âš ï¸ OpenAI ë¯¸ì‚¬ìš©: '{raw_name}' -> ê·œì¹™ ê¸°ë°˜ ì²˜ë¦¬")
            return self.clean_recipe_name(raw_name)
        
        # OpenAI APIìš© í”„ë¡¬í”„íŠ¸ (ë” ëª…í™•í•œ ì§€ì‹œì‚¬í•­)
        prompt = f"""ë ˆì‹œí”¼ ì œëª©ì—ì„œ í•µì‹¬ ìš”ë¦¬ëª…ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.

ì œê±°í•  ê²ƒ:
- ìˆ«ì, ë‚ ì§œ, ì—í”¼ì†Œë“œ ë²ˆí˜¸
- ìˆ˜ì‹ì–´(ë§›ìˆëŠ”, ê°„ë‹¨í•œ, ì•„ì‚­í•œ, ì…ë§›ë‹êµ¬ëŠ” ë“±)
- ì¡°ë¦¬ë°©ë²• ê´€ë ¨ ë‹¨ì–´(ë§Œë“œëŠ”ë²•, ë ˆì‹œí”¼, ë§Œë“¤ê¸°, í™©ê¸ˆë ˆì‹œí”¼ ë“±)
- íŠ¹ìˆ˜ë¬¸ì(!,.,.. ë“±)

ì˜ˆì‹œ:
ì…ë ¥: [176.ì˜¤íŠ¸ë°€ê³¼ì¼ë¹µ(2025.11.7)]
ì¶œë ¥: ì˜¤íŠ¸ë°€ê³¼ì¼ë¹µ

ì…ë ¥: [[ë§Œê°œë°±ê³¼] EP. 18 ê°€ë” ìƒê°ë‚˜ëŠ” ì•¼ì±„ìƒëŸ¬ë“œë¹µ]
ì¶œë ¥: ì•¼ì±„ìƒëŸ¬ë“œë¹µ

ì…ë ¥: [ì—ì–´í”„ë¼ì´ì–´ ìš”ë¦¬ ì–‘íŒŒí–„ì¹˜ì¦ˆë¹µ ë§Œë“œëŠ” ë²• ë„ˆë¬´ ë§›ìˆì–ì•„]
ì¶œë ¥: ì–‘íŒŒí–„ì¹˜ì¦ˆë¹µ

ì…ë ¥: [ì•„ì‚­í•œ ì½©ë‚˜ë¬¼ë¬´ì¹¨ ë ˆì‹œí”¼ ë§Œë“¤ê¸°]
ì¶œë ¥: ì½©ë‚˜ë¬¼ë¬´ì¹¨

ì…ë ¥: [ì…ë§› ë‹êµ¬ëŠ” ì–‘íŒŒë®ë°¥ ë ˆì‹œí”¼!]
ì¶œë ¥: ì–‘íŒŒë®ë°¥

ì…ë ¥: [{raw_name}]
ì¶œë ¥:"""

        try:
            # OpenAI API í˜¸ì¶œ
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ìš”ë¦¬ ëª…ì¹­ ì •ì œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•µì‹¬ ìš”ë¦¬ëª…ë§Œ ì¶”ì¶œí•˜ê³ , ìˆ˜ì‹ì–´ì™€ ì¡°ë¦¬ë°©ë²• ê´€ë ¨ ë‹¨ì–´ëŠ” ëª¨ë‘ ì œê±°í•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=20,
                temperature=0.0,
            )
            
            refined = response.choices[0].message.content.strip()
            
            # í›„ì²˜ë¦¬: ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°
            refined = re.sub(r'ì¶œë ¥:|ê²°ê³¼:|->|:|\*|```|!|\.|â€¦', '', refined).strip()
            refined = refined.split('\n')[0].strip()
            
            # ì¶”ê°€ ì •ì œ: ë‚¨ì€ ë¶ˆí•„ìš”í•œ ë‹¨ì–´ ì œê±°
            noise_words = ['ë ˆì‹œí”¼', 'ë§Œë“¤ê¸°', 'ë§Œë“œëŠ”ë²•', 'í™©ê¸ˆë ˆì‹œí”¼']
            for word in noise_words:
                refined = refined.replace(word, '').strip()
            
            # ê²€ì¦: ê²°ê³¼ê°€ ìœ íš¨í•œì§€ í™•ì¸
            if refined and len(refined) >= 2 and not refined.isdigit():
                print(f"âœ… OpenAI ì •ì œ: '{raw_name}' -> '{refined}'")
                return refined
            else:
                print(f"âš ï¸ OpenAI ê²°ê³¼ ë¶ˆëŸ‰: '{refined}' -> ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì²´")
                return self.clean_recipe_name(raw_name)
            
        except Exception as e:
            print(f"âš ï¸ OpenAI API ì˜¤ë¥˜: {e}")
            print(f"   '{raw_name}' -> ê·œì¹™ ê¸°ë°˜ ì²˜ë¦¬")
            return self.clean_recipe_name(raw_name)

    def clean_recipe_name(self, name):
        """
        [ê³ ë„í™”ëœ ì •ì œ] ìì·¨ìƒìš© ìˆ˜ì‹ì–´ ì œê±° (ì–´ìˆœ ìœ ì§€)
        """
        # 1. íŠ¹ìˆ˜ë¬¸ìë¥¼ ê³µë°±ìœ¼ë¡œ ë³€í™˜ (ê´„í˜¸, ëŒ€ê´„í˜¸, ì  ë“±)
        name = re.sub(r'[\[\]().,\-_]', ' ', name)
        
        # 2. ìˆ«ìì™€ ë‚ ì§œ íŒ¨í„´ ì œê±° (ì˜ˆ: 176, 2025.11.7, EP 18)
        name = re.sub(r'\d+\.?\d*\.?\d*', ' ', name)
        name = re.sub(r'ep\s*\d+|episode\s*\d+', ' ', name, flags=re.IGNORECASE)
        
        # 3. ì†Œë¬¸ì ë³€í™˜
        name = name.lower()
        
        # 4. ë…¸ì´ì¦ˆ ë‹¨ì–´ ì œê±°
        stop_words = [
            'ë ˆì‹œí”¼', 'ë§Œë“¤ê¸°', 'ë°©ë²•', 'í™©ê¸ˆë ˆì‹œí”¼', 'ê°„ë‹¨', 'ì´ˆê°„ë‹¨', 'ì•„ì‚­í•œ', 'ë§›ìˆëŠ”', 
            'ê¿€íŒ', 'ì§‘ë°¥', 'ë°˜ì°¬', 'ì–‘ë…', 'ì “êµ­', 'í•˜ì–€', 'ì‹ê°ì´', 'ë§¤ë ¥ì ì¸', 'ë‹¨ì§ ', 
            'ì…ë§›ë‹ê¶ˆì£¼ëŠ”', 'ìƒˆì½¤ì•„ì‚­', 'ë“ ë“ í•œ', 'ìµœê³ ì˜', 'ë“ì´ëŠ”ë²•', 'ë“ì´ê¸°', 'ì¡°ë¦¬ë²•',
            'ìš”ë¦¬ë²•', 'ì‰¬ìš´', 'ë¹ ë¥¸', 'íŠ¹ê¸‰', 'ë¹„ë²•', 'í™©ê¸ˆ', 'ê¿€', 'ë°±ì„ ìƒ', 'ì•Œí† ë€',
            'ì…ë§›', 'ë‹êµ¬ëŠ”', 'ê°„ë‹¨í•˜ì§€ë§Œ', 'íŠ¹ë³„í•œ', 'ì˜ì–‘ë§Œì ', 'ì´ˆìŠ¤í”¼ë“œ', 'ì†ì„±',
            'ë§Œê°œë°±ê³¼', 'ê°€ë”', 'ìƒê°ë‚˜ëŠ”', 'ë„ˆë¬´', 'ë§›ìˆì–ì•„', 'ì—ì–´í”„ë¼ì´ì–´', 'ìš”ë¦¬',
            'ë§Œë“œëŠ”', 'ë²•', 'ë²•', 'ep', 'episode'
        ]
        
        words = name.split()
        # ì–´ìˆœ ìœ ì§€í•˜ë©´ì„œ ë¶ˆìš©ì–´ë§Œ ì œê±°
        cleaned_words = [w for w in words if w.strip() and w not in stop_words]
        
        # ì¤‘ë³µ ì œê±°í•˜ë˜ ìˆœì„œëŠ” ìœ ì§€
        unique_words = []
        for w in cleaned_words:
            if w not in unique_words and len(w) > 0:
                unique_words.append(w)
        
        result = " ".join(unique_words).strip()
        
        # ê²°ê³¼ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì›ë³¸ì˜ ì²« ë‹¨ì–´ë¼ë„ ë°˜í™˜
        if not result and words:
            result = words[0]
                
        return result

    def is_too_similar(self, new_name, existing_names, threshold=0.6):
        """
        [ì¤‘ë³µë„ ê²€ì‚¬] Overlap Coefficientë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ìŠ·í•œ ë©”ë‰´ ì¤‘ë³µ ë°©ì§€
        """
        new_set = set(new_name.split())
        if not new_set: return True

        for existing in existing_names:
            existing_set = set(existing.split())
            if not existing_set: continue
            
            # ë‹¨ì–´ ì¤‘ë³µ ë¹„ìœ¨ ê³„ì‚°
            intersection = new_set.intersection(existing_set)
            overlap = len(intersection) / min(len(new_set), len(existing_set))
            
            if overlap >= threshold:
                return True
        return False

    def get_embedding(self, text: str) -> list:
        """ë¡œì»¬ SentenceTransformer ëª¨ë¸ë¡œ ì„ë² ë”© ìƒì„± (768ì°¨ì›)"""
        try:
            return self.model.encode(text).tolist()
        except Exception as e:
            print(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    def hybrid_search(self, user_ingredients, n_results=5):
        """
        ë²¡í„° ìœ ì‚¬ë„(60%) + í‚¤ì›Œë“œ ë§¤ì¹­(40%) + ìì·¨ìƒìš© ë‹¤ì–‘ì„± í•„í„°
        """
        # ë¡œì»¬ ëª¨ë¸ìš©: reindex.pyì™€ ë™ì¼í•œ í˜•ì‹ìœ¼ë¡œ ì¿¼ë¦¬ ìƒì„±
        ingredients_text = ", ".join(user_ingredients)
        query_text = f"ìš”ë¦¬ëª…: , ì¬ë£Œ: {ingredients_text}"
        query_vector = self.get_embedding(query_text)

        if query_vector is None:
            print("âš ï¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨, ë¹ˆ ê²°ê³¼ ë°˜í™˜")
            return []
        
        # ì¤‘ë³µì„ ê±¸ëŸ¬ë‚´ê³ ë„ 5ê°œë¥¼ ì±„ìš°ê¸° ìœ„í•´ ì¶©ë¶„í•œ í›„ë³´(75ê°œ) ì¶”ì¶œ
        results = self.collection.query(
            query_embeddings=[query_vector],
            n_results=n_results * 15 
        )
        
        hybrid_results = []
        final_names = [] 

        for i in range(len(results['ids'][0])):
            metadata = results['metadatas'][0][i]
            raw_name = metadata['name']
            cleaned_name = self.clean_recipe_name(raw_name)
            
            # ê¸°ì¡´ ê²°ê³¼ì™€ ë„ˆë¬´ ë¹„ìŠ·í•˜ë©´ ê±´ë„ˆëœ€ (ë‹¤ì–‘ì„± í™•ë³´)
            if self.is_too_similar(cleaned_name, final_names):
                continue
            
            recipe_ingredients = json.loads(metadata['ingredients'])
            vector_score = 1 - results['distances'][0][i]
            match_count = sum(1 for ing in user_ingredients if ing in recipe_ingredients)
            keyword_score = match_count / len(user_ingredients) if user_ingredients else 0
            
            final_score = (vector_score * 0.6) + (keyword_score * 0.4)
            
            hybrid_results.append({
                "name": cleaned_name,
                "original_name": raw_name,
                "score": round(final_score * 100, 2),
                "ingredients": recipe_ingredients,
                "url": metadata.get('blog_url', 'ì •ë³´ ì—†ìŒ')
            })
            final_names.append(cleaned_name)
            
            if len(hybrid_results) == n_results:
                break
        
        # ë°˜í™˜ ì§ì „ ìµœì¢… 5ê°œì— ëŒ€í•´ì„œë§Œ OpenAI LLM ì •ì œ ìˆ˜í–‰
        print("ğŸª„ ìœ íŠœë¸Œ ê²€ìƒ‰ ìµœì í™”ë¥¼ ìœ„í•´ ìš”ë¦¬ëª…ì„ ì •ì œ ì¤‘ì…ë‹ˆë‹¤...")
        for res in hybrid_results:
            res['name'] = self.clean_with_llm(res['original_name'])

        return hybrid_results

# --- í…ŒìŠ¤íŠ¸ ë° í†µí•©ìš© ì¶œë ¥ ì½”ë“œ ---
if __name__ == "__main__":
    searcher = RecipeSearcher()
    ocr_output = ["ê°ì", "ë‹¹ê·¼", "ì• í˜¸ë°•", "ë¼ì§€ê³ ê¸°"]
    
    print(f"\nğŸ›’ [ìì·¨ìƒ ëª¨ë“œ] ì¸ì‹ëœ ì‹ì¬ë£Œ: {ocr_output}")
    print("ğŸš€ ì¤‘ë³µ ì—†ëŠ” ê³ ë„í™”ëœ ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n")
    
    top_recipes = searcher.hybrid_search(ocr_output, n_results=5)
    
    print("="*50)
    print("ğŸ³ SaveMyDinner: ì˜¤ëŠ˜ì˜ ì¶”ì²œ ë ˆì‹œí”¼")
    print("="*50)
    for idx, r in enumerate(top_recipes, 1):
        print(f"{idx}. {r['name']} (ì í•©ë„: {r['score']}%)")
        print(f"   [ì¶œì²˜: {r['original_name']}]")
        print(f"   ğŸ”— {r['url']}")
        print("-" * 50)
    
    # ìˆ˜ë¯¼ì´ì—ê²Œ ì „ë‹¬í•  ìµœì¢… ìš”ë¦¬ëª… ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì¶œë ¥
    recipe_names = [r['name'] for r in top_recipes]
    print(f"âœ… ìµœì¢… ì „ë‹¬í•  ì •ì œëœ ìš”ë¦¬ëª… 5ê°œ: {recipe_names}")