"""
modules.vector_db.search
ì‘ì„±ì: ì¶”ìœ¤ì„œ
ê¸°ëŠ¥: ìì·¨ìƒ/1ì¸ ê°€êµ¬ ë§ì¶¤í˜• ë ˆì‹œí”¼ ì •ì œ ë° ì¤‘ë³µ ì œê±° ê²€ìƒ‰ ì—”ì§„
"""
import chromadb
import json
import re
# import os  # OpenAI ëª¨ë¸ ì‚¬ìš© ì‹œ í•„ìš”
from sentence_transformers import SentenceTransformer
# from openai import OpenAI  # OpenAI ëª¨ë¸ ì‚¬ìš© ì‹œ
# from dotenv import load_dotenv  # OpenAI API í‚¤ ì‚¬ìš© ì‹œ í•„ìš”

# load_dotenv()  # OpenAI API í‚¤ ì‚¬ìš© ì‹œ í•„ìš”

class RecipeSearcher:
    def __init__(self, db_path="./modules/vector_db/vectordb_recipes"):
        """
        ì´ˆê¸°í™”: ë¡œì»¬ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ë° ChromaDB ì—°ê²°
        """

        # 1. HuggingFaceì˜ í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ (768ì°¨ì›)
        self.model = SentenceTransformer('jhgan/ko-sroberta-multitask')

        # # 1. OpenAI í´ë¼ì´ì–¸íŠ¸ (1536ì°¨ì›)
        # api_key = os.getenv('OPENAI_API_KEY')
        # if api_key:
        #     self.openai_client = OpenAI(api_key=api_key)
        # else:
        #     print("âš ï¸ OPENAI_API_KEY not found - VectorDB search will be limited")
        #     self.openai_client = None

        # 2. ChromaDB í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
        self.client = chromadb.PersistentClient(path=db_path)

        # 3. ì»¬ë ‰ì…˜ ë¡œë“œ
        try:
            # recipes_local_cosine ì»¬ë ‰ì…˜ ìš°ì„  ë¡œë“œ (ë¡œì»¬ ëª¨ë¸ìš©)
            self.collection = self.client.get_collection(name="recipes_local_cosine")
            print(f"âœ… 'recipes_local_cosine' ì»¬ë ‰ì…˜ ë¡œë“œ ì™„ë£Œ. (ë°ì´í„°: {self.collection.count()}ê°œ)")

            # # ë¨¼ì € recipes_1000 ì‹œë„ (temp ë°ì´í„°)
            # try:
            #     self.collection = self.client.get_collection(name="recipes_1000")
            #     print(f"âœ… 'recipes_1000' ì»¬ë ‰ì…˜ ë¡œë“œ ì™„ë£Œ. (ë°ì´í„°: {self.collection.count()}ê°œ)")
            # except:
            #     # ì—†ìœ¼ë©´ recipes_local_cosine ì‹œë„ (ê¸°ì¡´ ì´ë¦„)
            #     self.collection = self.client.get_collection(name="recipes_local_cosine")
            #     print(f"âœ… 'recipes_local_cosine' ì»¬ë ‰ì…˜ ë¡œë“œ ì™„ë£Œ. (ë°ì´í„°: {self.collection.count()}ê°œ)")
        except Exception as e:
            print(f"âŒ ì»¬ë ‰ì…˜ ë¡œë“œ ì‹¤íŒ¨: {e}")

    def clean_recipe_name(self, name):
        """
        [ê³ ë„í™”ëœ ì •ì œ] ìì·¨ìƒìš© ìˆ˜ì‹ì–´ ì œê±° ë° ë‹¨ì–´ ì •ë ¬ ì •ê·œí™”
        """
        name = re.sub(r'[^\w\s]', ' ', name).lower()
        
        # 1ì¸ ê°€êµ¬ì—ê²Œ ë…¸ì´ì¦ˆê°€ ë˜ëŠ” ë‹¨ì–´ë“¤ ëŒ€í­ ì œê±°
        stop_words = [
            'ë ˆì‹œí”¼', 'ë§Œë“¤ê¸°', 'ë°©ë²•', 'í™©ê¸ˆë ˆì‹œí”¼', 'ê°„ë‹¨', 'ì´ˆê°„ë‹¨', 'ì•„ì‚­í•œ', 'ë§›ìˆëŠ”', 
            'ê¿€íŒ', 'ì§‘ë°¥', 'ë°˜ì°¬', 'ì–‘ë…', 'ì “êµ­', 'í•˜ì–€', 'ì‹ê°ì´', 'ë§¤ë ¥ì ì¸', 'ë‹¨ì§ ', 
            'ì…ë§›ë‹ê¶ˆì£¼ëŠ”', 'ìƒˆì½¤ì•„ì‚­', 'ë“ ë“ í•œ', 'ìµœê³ ì˜'
        ]
        
        words = name.split()
        # ì–´ìˆœ ì •ê·œí™”: ë‹¨ì–´ë¥¼ ê°€ë‚˜ë‹¤ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ 'í•˜ì–€ ì½©ë‚˜ë¬¼'ê³¼ 'ì½©ë‚˜ë¬¼ í•˜ì–€'ì„ ë™ì¼í•˜ê²Œ ì²˜ë¦¬
        cleaned_words = sorted([w for w in words if w not in stop_words])
        
        unique_words = []
        for w in cleaned_words:
            if w not in unique_words:
                unique_words.append(w)
                
        return " ".join(unique_words).strip()

    def is_too_similar(self, new_name, existing_names, threshold=0.6):
        """
        [ì¤‘ë³µë„ ê²€ì‚¬] Overlap Coefficientë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ìŠ·í•œ ë©”ë‰´ ì¤‘ë³µ ë°©ì§€
        """
        new_set = set(new_name.split())
        if not new_set: return True

        for existing in existing_names:
            existing_set = set(existing.split())
            if not existing_set: continue
            
            # ë‹¨ì–´ ì¤‘ë³µ ë¹„ìœ¨ ê³„ì‚°
            intersection = new_set.intersection(existing_set)
            overlap = len(intersection) / min(len(new_set), len(existing_set))
            
            if overlap >= threshold:
                return True
        return False

    def get_embedding(self, text: str) -> list:
        """ë¡œì»¬ SentenceTransformer ëª¨ë¸ë¡œ ì„ë² ë”© ìƒì„± (768ì°¨ì›)"""
        try:
            return self.model.encode(text).tolist()
        except Exception as e:
            print(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    # def get_embedding(self, text: str) -> list:
    #     """OpenAI APIë¡œ ì„ë² ë”© ìƒì„± (1536ì°¨ì›)"""
    #     if self.openai_client is None:
    #         return None
    #
    #     try:
    #         response = self.openai_client.embeddings.create(
    #             model="text-embedding-3-small",
    #             input=text
    #         )
    #         return response.data[0].embedding
    #     except Exception as e:
    #         print(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
    #         return None

    def hybrid_search(self, user_ingredients, n_results=5):
        """
        ë²¡í„° ìœ ì‚¬ë„(60%) + í‚¤ì›Œë“œ ë§¤ì¹­(40%) + ìì·¨ìƒìš© ë‹¤ì–‘ì„± í•„í„°
        """
        # ë¡œì»¬ ëª¨ë¸ìš©: reindex.pyì™€ ë™ì¼í•œ í˜•ì‹ìœ¼ë¡œ ì¿¼ë¦¬ ìƒì„±
        ingredients_text = ", ".join(user_ingredients)
        query_text = f"ìš”ë¦¬ëª…: , ì¬ë£Œ: {ingredients_text}"
        query_vector = self.get_embedding(query_text)

        # # OpenAI ëª¨ë¸ìš©: DB êµ¬ì¶• ì‹œ ì‚¬ìš©í•œ í˜•ì‹ê³¼ ë™ì¼í•˜ê²Œ ì¿¼ë¦¬ ìƒì„±
        # ingredients_text = ", ".join(user_ingredients)
        # query_text = f"ì¬ë£Œ: {ingredients_text}. ì´ ì¬ë£Œë“¤ë¡œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ìš”ë¦¬ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”."
        # query_vector = self.get_embedding(query_text)

        if query_vector is None:
            print("âš ï¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨, ë¹ˆ ê²°ê³¼ ë°˜í™˜")
            return []
        
        # ì¤‘ë³µì„ ê±¸ëŸ¬ë‚´ê³ ë„ 5ê°œë¥¼ ì±„ìš°ê¸° ìœ„í•´ ì¶©ë¶„í•œ í›„ë³´(75ê°œ) ì¶”ì¶œ
        results = self.collection.query(
            query_embeddings=[query_vector],
            n_results=n_results * 15 
        )
        
        hybrid_results = []
        final_names = [] 

        for i in range(len(results['ids'][0])):
            metadata = results['metadatas'][0][i]
            raw_name = metadata['name']
            cleaned_name = self.clean_recipe_name(raw_name)
            
            # ê¸°ì¡´ ê²°ê³¼ì™€ ë„ˆë¬´ ë¹„ìŠ·í•˜ë©´ ê±´ë„ˆëœ€ (ë‹¤ì–‘ì„± í™•ë³´)
            if self.is_too_similar(cleaned_name, final_names):
                continue
            
            recipe_ingredients = json.loads(metadata['ingredients'])
            vector_score = 1 - results['distances'][0][i]
            match_count = sum(1 for ing in user_ingredients if ing in recipe_ingredients)
            keyword_score = match_count / len(user_ingredients) if user_ingredients else 0
            
            final_score = (vector_score * 0.6) + (keyword_score * 0.4)
            
            hybrid_results.append({
                "name": cleaned_name,
                "original_name": raw_name,
                "score": round(final_score * 100, 2),
                "ingredients": recipe_ingredients,
                "url": metadata.get('blog_url', 'ì •ë³´ ì—†ìŒ')
            })
            final_names.append(cleaned_name)
            
            if len(hybrid_results) == n_results:
                break
        
        return hybrid_results

# --- í…ŒìŠ¤íŠ¸ ë° í†µí•©ìš© ì¶œë ¥ ì½”ë“œ ---
if __name__ == "__main__":
    searcher = RecipeSearcher()
    ocr_output = ["ì½©ë‚˜ë¬¼", "ë§ˆëŠ˜", "ëŒ€íŒŒ"]
    
    print(f"\nğŸ›’ [ìì·¨ìƒ ëª¨ë“œ] ì¸ì‹ëœ ì‹ì¬ë£Œ: {ocr_output}")
    print("ğŸš€ ì¤‘ë³µ ì—†ëŠ” ê³ ë„í™”ëœ ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n")
    
    top_recipes = searcher.hybrid_search(ocr_output, n_results=5)
    
    print("="*50)
    print("ğŸ³ SaveMyDinner: ì˜¤ëŠ˜ì˜ ì¶”ì²œ ë ˆì‹œí”¼")
    print("="*50)
    for idx, r in enumerate(top_recipes, 1):
        print(f"{idx}. {r['name']} (ì í•©ë„: {r['score']}%)")
        print(f"   [ì¶œì²˜: {r['original_name']}]")
        print(f"   ğŸ”— {r['url']}")
        print("-" * 50)
    
    # ìˆ˜ë¯¼ì´ì—ê²Œ ì „ë‹¬í•  ìµœì¢… ìš”ë¦¬ëª… ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì¶œë ¥
    recipe_names = [r['name'] for r in top_recipes]
    print(f"âœ… ìµœì¢… ì „ë‹¬í•  ì •ì œëœ ìš”ë¦¬ëª… 5ê°œ: {recipe_names}")